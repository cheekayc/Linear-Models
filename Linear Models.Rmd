---
title: "Linear Models"
author: "Lectured by Jeff Goldsmith"
date: "2022-11-10"
output: github_document
---

```{r setup, eval = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

library(tidyverse)
library(p8105.datasets)

set.seed(1)
```

**Check this [page](https://www.statology.org/t-test-linear-regression/) for simple explanation of linear regression.**

## *Model Fitting*

* `lm` = linear models (continuous outcome)

* `glm` = generalized linear models (non-continuous outcome)

* Use ***broom package*** for output

Load and clean `nyc_airbnb` dataset.
```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    borough = neighbourhood_group,
    neighborhood = neighbourhood) %>% 
  filter(borough != "Staten Island") %>% # because Staten Island data is too small. Not meaningful to analyze that.
  select(price, stars, borough, neighborhood, room_type)
```

Fit a linear model to look at how **price** (outcome) changes with **rating** and **borough**.
```{r}
model = lm(price ~ stars + borough, data = nyc_airbnb)
# Regression equation: price = -70.41 + 31.99*stars + 40.50*Brooklyn + 90.25*Manhattan + 13.21*Queens

model 
# Up to this point, we only get the coefficients of each variable.

summary(model) 
# Summary will give us a lot of information, such as standard error, t-value, p-value, r-squared, etc.

# To output the results in a tidy way, use broom::tidy.
model %>% 
  broom::tidy() %>% 
  mutate(
    term = str_replace(term, "borough", "Borough: ")) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 2)
```



In the example above, Bronx is the reference category according to alphabetical order.                                                      
What if we want to change the reference category?
```{r}
model_chng_ref = 
  nyc_airbnb %>% 
  mutate(
    borough = fct_infreq(borough)) %>% # Now the most common category would be the reference group.
  lm(price ~ stars + borough, data = .)

model_chng_ref %>% 
  broom::tidy() %>% 
  mutate(
    term = str_replace(term, "borough", "Borough: ")) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 2)
```

##### `broom::glance`

* `broom::tidy` gives us estimate, std.error, statistics (t-test?), and p-value.

* `broom::glance` gives us r-squared, adj.r-squared, sigma, statistic, p-value, df, logLik, AIC, BIC, deviance, df.residual, n_obs

```{r}
model %>% 
  broom::glance() %>%
  select(r.squared, p.value, AIC)
```


## **Diagnostics**

The **fitted** (or predicted) values are the y-values that you would expect for the given x-values according to the built regression model
(or visually, the best-fitting straight regression line).

To use linear regression, the following assumptions must be met:                                                                     
1) **Linearity**: The relationship between the independent and dependent variables is linear. 
  * Check this assumption by examining a scatterplot of x and y.  
  
2) **Homoscedasticity**: The variance of residual is the same for any value of X.
  * Check this assumption by examining the scatterplot of “residuals versus fits”; the variance of the residuals should be the same across
  all values of the x-axis. If the plot shows a pattern (e.g., bowtie or megaphone shape), then variances are not consistent, and this
  assumption has not been met.
  
3) **Independence**: Observations are independent of each other (not repeated by the same person, don't live in same household, not siblings, etc.)
There is not a relationship between the residuals and the variable; in other words, is independent of errors. 
  * Check this assumption by examining a scatterplot of “residuals versus fits”; the correlation should be approximately 0. In other words, 
  there should not look like there is a relationship.
  
4) **Normality**: The residuals must be approximately normally distributed.
  * Check this assumption by examining a normal probability plot; the observations should be near the line. You can also examine a histogram 
  of the residuals; it should be approximately normally distributed.

```{r}
modelr::add_residuals(nyc_airbnb, model) %>% 
  ggplot(aes(x = stars, y = resid)) +
  geom_point()

nyc_airbnb %>% 
  modelr::add_residuals(model) %>% 
  ggplot(aes(x = borough, y = resid)) +
  geom_violin() +
  ylim(-250, 250)
# From the plot, we can see that the variances are not constant. 
# Linear regression assumes constant residuals.. So this assumption is violated.
```


## Hypothesis Testing

one coefficient
```{r}
model_chng_ref %>% 
  broom::tidy()

H_null = lm(price ~ stars, data = nyc_airbnb)
H_alt = lm(price ~ stars + borough, data = nyc_airbnb)

anova(H_null, H_alt) %>% 
  broom::tidy()
  
```

## Room type by borough

Interactions?

```{r}
model_int = 
  nyc_airbnb %>% 
  lm(price ~ stars + borough * room_type, data = .)

model_int %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Can we fit models by borough?
```{r}
nyc_airbnb %>% 
  nest(df = -borough) %>% 
  mutate(
    models = map(.x = df, ~lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)) %>% 
  pull(results)

nyc_airbnb %>% 
  nest(df = -borough) %>% 
  mutate(
    models = map(.x = df, ~lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(borough, results) %>% 
  unnest(results)
```

```{r}
nyc_airbnb %>% 
  filter(borough == "Bronx") %>% 
  lm(price ~ stars + room_type, data = .) %>% 
  broom::tidy()
```



